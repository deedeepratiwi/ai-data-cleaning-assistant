ğŸ¬ AI Data Cleaning Assistant â€” Demo Script

â±ï¸ Total time: ~6 minutes

Audience: technical reviewers, hiring managers, early users

0ï¸âƒ£ Intro (30 seconds)

â€œThis project is an AI-powered data cleaning assistant.
Users upload a raw CSV file, and the system automatically profiles the data, generates cleaning suggestions using an LLM, applies transformations, and returns a cleaned dataset â€” all fully automated and orchestrated.â€

(Optional add:)

â€œThe system is built with FastAPI, MCP for AI intelligence, and n8n for orchestration.â€

1ï¸âƒ£ Show Architecture (45 seconds)

Open docs/architecture.md or say verbally:

â€œThe architecture is split into three layers:
- Main API: owns jobs, files, and state
- MCP server: handles LLM-based reasoning
- n8n: orchestrates the pipeline steps

This separation makes the system safe, scalable, and replaceable.â€

Key line (important for reviewers):

â€œn8n contains no business logic â€” it only coordinates API calls.â€

Start the System (30 seconds)

Terminal:

docker compose up --build


Say:

â€œEverything runs locally via Docker Compose â€” API, MCP server, and n8n.â€

Open:

API: http://localhost:8000/docs

n8n: http://localhost:5678

3ï¸âƒ£ Upload a CSV File (1 minute)

Use Swagger UI or curl.

Example CSV (mention verbally)

â€œThis CSV contains missing values, inconsistent types, and unnecessary columns.â€

Swagger:

POST /jobs/upload


Upload a file like raw_customers.csv.

Response:

{
  "job": {
    "id": "42438666-d8f5-4952-b514-c292ad66d8c0",
    "status": "pending"
  }
}


Say:

â€œUploading a file creates a job and stores the raw data.â€

4ï¸âƒ£ Trigger the AI Pipeline (45 seconds)
POST /jobs/{job_id}/run


Say:

â€œThis triggers an n8n workflow via a webhook.
From here, everything is asynchronous and automated.â€


5ï¸âƒ£ Show n8n Workflow Running (1 minute)

Open n8n UI â†’ Workflow executions.

Explain each step:
- Profiling
- AI suggestions (via MCP)
- Apply transformations

Key line:

â€œEach step is retryable and idempotent. Failures donâ€™t corrupt job state.â€

6ï¸âƒ£ Job Completion (30 seconds)

Check job status:

GET /jobs/{job_id}


Response:

{
  "status": "done"
}


Say:

â€œOnce the job reaches done, the cleaned dataset is available.â€


7ï¸âƒ£ Download Cleaned Data (45 seconds)
GET /jobs/{job_id}/download


Browser downloads:

42438666_cleaned.csv


Open it briefly and show:
- Fewer nulls
- Cleaned columns
- Consistent types

Say:

â€œThis is the final cleaned dataset, ready for analysis or ML.â€

8ï¸âƒ£ Why This Matters (45 seconds)

Close with:

â€œThis project demonstrates:
- Real AI integration using MCP
- Production-grade orchestration with n8n
- Clean system boundaries
- End-to-end automation

Itâ€™s not a notebook demo â€” itâ€™s a real, deployable system.â€

Optional:

â€œThis can be sold as a self-hosted workflow, API service, or internal data tool.â€

Demo Checklist (Before Recording)
- Docker builds clean
- Sample CSV ready
- n8n workflow imported
- Swagger UI loads
- Download endpoint works